{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6110b5",
   "metadata": {},
   "source": [
    "### Data source: https://www.bracs.icar.cnr.it/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd0608",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from geojson import GeoJSON\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import shapely\n",
    "from rtree import index\n",
    "from shapely.ops import cascaded_union, unary_union\n",
    "from shapely.plotting import plot_polygon\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from openslide import OpenSlide\n",
    "\n",
    "from tiatoolbox import utils\n",
    "from tiatoolbox.wsicore import wsireader\n",
    "from tiatoolbox import data\n",
    "from tiatoolbox.tools import stainnorm\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "# Load config\n",
    "preproc_conf = OmegaConf.load(\"../conf/preproc.yaml\")\n",
    "preproc_conf = preproc_conf['classic_mil_on_embeddings_bag']['bracs_224_224_patches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127988cb-ed75-4641-bb75-7306e1f69093",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs( preproc_conf.cv_split_dir, exist_ok=True ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695306a-0905-49a2-869e-3d3ef3bf0d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_conf.data_root_dir+'BRACS.xlsx', preproc_conf.cv_split_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53eed3-c661-4a01-8863-48bc61193313",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_from = preproc_conf.data_root_dir+'BRACS.xlsx'\n",
    "cp_to = preproc_conf.cv_split_dir\n",
    "!cp -rp $cp_from $cp_to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c4c9b",
   "metadata": {},
   "source": [
    "### Locate annotations"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bb19f28",
   "metadata": {},
   "source": [
    "!pip install tiatoolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_folder = preproc_conf.annotation_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list = np.array( sorted( [ i for i in os.listdir(annotation_folder) if 'geo' in i ] ) )\n",
    "annotation_list.shape, annotation_list[:10]\n",
    "# only on 387 slides are annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52468d8-0707-43b3-ad05-b772a5438a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "bracs_df = pd.read_excel(preproc_conf.cv_split_dir+'BRACS.xlsx')\n",
    "bracs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b77ad-1625-4337-b98a-54edf0a5db9e",
   "metadata": {},
   "source": [
    "##### CHECK FOR LEAKS IN BRACS SPLIT !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a43de-33b3-4419-8ba1-a4463acfb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Patient Id and count the number of unique sets they appear in\n",
    "patient_set_overlap = bracs_df.groupby('Patient Id')['Set'].nunique()\n",
    "\n",
    "# Filter the patients that appear in more than one set\n",
    "leaked_patients = patient_set_overlap[patient_set_overlap > 1]\n",
    "leaked_patients.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36cc9b-5ed5-41ea-bd0d-53bbed9af35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bracs_df[ bracs_df['Patient Id'] == 67 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a84953-82b5-43e4-b2cf-0c5b8dba2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'Set' column to 'Validation' for all rows where 'Patient Id' is 67\n",
    "bracs_df.loc[bracs_df['Patient Id'] == 67, 'Set'] = 'Validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acaad23-daf6-40a3-a323-ad6ad0276ebb",
   "metadata": {},
   "source": [
    "##### check again for leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a8246-3c50-4c44-a6ae-d0f23e6e705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Patient Id and count the number of unique sets they appear in\n",
    "patient_set_overlap = bracs_df.groupby('Patient Id')['Set'].nunique()\n",
    "\n",
    "# Filter the patients that appear in more than one set\n",
    "leaked_patients = patient_set_overlap[patient_set_overlap > 1]\n",
    "leaked_patients.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792ca36-84c3-4d3d-abac-c9f9e668b7fc",
   "metadata": {},
   "source": [
    "#### extract info from their splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7813179c-47b9-4cb1-89b1-02661cb2a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_training_candidate = np.array( [ bracs_df['WSI Filename'].iloc[k]+'.geojson' for k in range(bracs_df.shape[0]) if bracs_df.Set.iloc[k] == 'Training' ] )\n",
    "annotation_list_training_candidate.shape, annotation_list_training_candidate[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00799419-54c8-46b8-bb33-5aee5deff6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_validation_candidate = np.array( [ bracs_df['WSI Filename'].iloc[k]+'.geojson' for k in range(bracs_df.shape[0]) if bracs_df.Set.iloc[k] == 'Validation' ] )\n",
    "annotation_list_validation_candidate.shape, annotation_list_validation_candidate[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c011787-f384-4cb9-a929-49430c326153",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_test_candidate = np.array( [ bracs_df['WSI Filename'].iloc[k]+'.geojson' for k in range(bracs_df.shape[0]) if bracs_df.Set.iloc[k] == 'Testing' ] )\n",
    "annotation_list_test_candidate.shape, annotation_list_test_candidate[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44999274-7274-4870-9a6a-a2e431f8217e",
   "metadata": {},
   "source": [
    "#### merge this info into WSI level annotations, not ROIs, as described at their approach\n",
    "\n",
    "we are extracting at magnification level 2.5x exactly!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4949ff3-c0d3-4362-bd5e-cb6b9108a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_training = annotation_list_training_candidate[ np.in1d( annotation_list_training_candidate, annotation_list ) ]\n",
    "annotation_list_training.shape, annotation_list_training[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2819e639-bcab-47d7-bec0-8ebfdfbee0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_validation = annotation_list_validation_candidate[ np.in1d( annotation_list_validation_candidate, annotation_list ) ]\n",
    "annotation_list_validation.shape, annotation_list_validation[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35547d11-0cdb-41d1-b7dc-aeb7f93a092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list_test = annotation_list_test_candidate[ np.in1d( annotation_list_test_candidate, annotation_list ) ]\n",
    "annotation_list_test.shape, annotation_list_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552a682",
   "metadata": {},
   "source": [
    "### Test process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18051641",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_fname = annotation_folder + annotation_list_training[260]\n",
    "\n",
    "with open(json_fname) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bdaefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapely.Polygon(np.array(data['features'][0]['geometry']['coordinates'][0])//16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631aaddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['features'][0]['properties']['classification']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_coords_all = []\n",
    "data_type_all = []\n",
    "data_label_all = []\n",
    "for feature in data['features']:\n",
    "    data_type = feature['geometry']['type']\n",
    "    data_type_all.append(data_type)\n",
    "    data_coords = feature['geometry']['coordinates'][0]\n",
    "    data_coords_all.append(data_coords)\n",
    "    data_label = feature['properties']['classification']['name']\n",
    "    data_label_all.append(data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca18dd",
   "metadata": {},
   "source": [
    "### Automate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd060356",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_bracs_old = np.array(['ADH', 'ADH-sure', 'BENIGN', 'Benign sure', 'Benign-sure', 'DCIS',\n",
    "       'DCIS-sure', 'FEA', 'FEA-sure', 'MALIGNANT', 'Malignant',\n",
    "       'Malignant-sure', 'Pathologica benign', 'Pathological-benign',\n",
    "       'Pathological-benign (Benign-sure)', 'UDH', 'UDH-sure'])\n",
    "\n",
    "\n",
    "annot_bracs_new = np.array(['ADH', 'ADH', 'NORMAL', 'NORMAL', 'NORMAL', 'DCIS',\n",
    "       'DCIS', 'FEA', 'FEA', 'INVASIVE-CARCINOMA', 'INVASIVE-CARCINOMA',\n",
    "       'INVASIVE-CARCINOMA', 'PATHOLOGICAL-BENIGN', 'PATHOLOGICAL-BENIGN',\n",
    "       'PATHOLOGICAL-BENIGN', 'UDH', 'UDH'])\n",
    "\n",
    "annot_map = dict(zip(annot_bracs_old, annot_bracs_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json( abspath ):\n",
    "    \n",
    "    with open(abspath) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data_polygon_all = []\n",
    "    data_label_all = []\n",
    "    for feature in data['features']:\n",
    "        \n",
    "\n",
    "        try:\n",
    "            \n",
    "            data_polygon = shapely.Polygon(np.array(feature['geometry']['coordinates'][0])//16)\n",
    "            data_polygon_all.append(data_polygon)\n",
    "        \n",
    "        except:\n",
    "            print(feature)\n",
    "            \n",
    "        \n",
    "        \n",
    "        data_label = feature['properties']['classification']['name']\n",
    "        data_label = annot_map[data_label] # map annots\n",
    "        data_label_all.append(data_label)\n",
    "    \n",
    "    # then create polygons and return that at the end instead of the coords\n",
    "    \n",
    "    return data_polygon_all, data_label_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_back_labels_and_polygons_for_set(annotation_list):\n",
    "    polygons_all = []\n",
    "    labels_all = []\n",
    "    \n",
    "    for i in range( len(annotation_list) ): \n",
    "        polygons, labels =  extract_json(annotation_folder+annotation_list[i])\n",
    "    \n",
    "        assert len(polygons) == len(labels)\n",
    "        \n",
    "        labels_all.append(labels)\n",
    "        polygons_all.append(polygons)\n",
    "        \n",
    "    #labels_all = np.concatenate(labels_all)\n",
    "    #polygons_all = np.concatenate(polygons_all)\n",
    "    print( len(labels_all), len(polygons_all) )\n",
    "\n",
    "    return labels_all, polygons_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01138b70-862d-4dc1-8c2d-a69c6f3327f9",
   "metadata": {},
   "source": [
    "### Get whole dataset and each partition according to BRACS paper ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3976a-0236-480b-a558-3768b99f5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all, polygons_all = give_back_labels_and_polygons_for_set(annotation_list) # whole set without partition !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed1497-7f20-4f13-a131-ed0ea7543b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_training, polygons_training = give_back_labels_and_polygons_for_set(annotation_list_training) # training set !\n",
    "labels_validation, polygons_validation = give_back_labels_and_polygons_for_set(annotation_list_validation) # validation set !\n",
    "labels_test, polygons_test = give_back_labels_and_polygons_for_set(annotation_list_test) # test set !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305953d0",
   "metadata": {},
   "source": [
    "### Check labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b625de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter( np.concatenate(labels_all) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0c450-d8dd-4aa5-9185-92174c61075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter( np.concatenate(labels_training) ) + Counter( np.concatenate(labels_validation) ) + Counter( np.concatenate(labels_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c186b6d",
   "metadata": {},
   "source": [
    "### Check images and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list[ [ len(labels_all[w]) > 50 for w in  range(385) ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9323db",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list[384], len(labels_all[384]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ab930",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi = OpenSlide(preproc_conf.WSI_root_dir+'BRACS_773.svs')\n",
    "print(wsi.level_dimensions[2])\n",
    "img = np.array( wsi.read_region((0,0), 2, wsi.level_dimensions[2]).convert('RGB') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a subplot\n",
    "fig = plt.figure(figsize=(img.shape[0]//200, img.shape[1]//200))  # Adjust the width and height as desired\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "#transposed_image = img_to_vis.transpose(Image.TRANSPOSE)\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot transparent polygons\n",
    "for p in range(len(polygons_all[384])):\n",
    "    pol = polygons_all[384][p]\n",
    "    plot_polygon(pol, ax, edgecolor='blue')\n",
    "    \n",
    "\n",
    "#plt.savefig('save_bracs_slides_'+wsi.properties['aperio.Filename'], dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de780666",
   "metadata": {},
   "source": [
    "#### Plotting big images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the 'labels_all' array with string labels\n",
    "# Function to create a colormap based on unique string labels\n",
    "#def create_color_map(labels):\n",
    "#    unique_labels = np.unique(labels)\n",
    "#    num_colors = len(unique_labels)\n",
    "#    color_map = plt.cm.get_cmap('Set1', num_colors)  # You can choose any colormap you like\n",
    "#    label_to_color = {label: color_map(idx) for idx, label in enumerate(unique_labels)}\n",
    "#    return label_to_color\n",
    "\n",
    "def create_color_map(labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    num_colors = len(unique_labels)\n",
    "\n",
    "    # Hand-picked colors that are visible on purple-red-pink background\n",
    "    good_colors = ['#61d2ff', '#ff7700', '#00ffaa', '#1687f7', '#02c415','#aa00ff', '#b8c202' ]\n",
    "\n",
    "    label_to_color = {label: good_colors[idx % len(good_colors)] for idx, label in enumerate(unique_labels)}\n",
    "    return label_to_color\n",
    "\n",
    "# Create a colormap based on string labels\n",
    "label_to_color = create_color_map(np.concatenate(labels_all))\n",
    "\n",
    "# Function to plot a polygon without nodes\n",
    "def plot_polygon_without_nodes(polygon, ax, edgecolor):\n",
    "    x, y = polygon.exterior.xy\n",
    "    ax.add_patch(Polygon(np.c_[x, y], edgecolor=edgecolor, facecolor=edgecolor, linewidth=3, alpha=0.5))\n",
    "\n",
    "# Add a subplot\n",
    "fig = plt.figure(figsize=(20, 20))  # Adjust the width and height as desired\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# transposed_image = img_to_vis.transpose(Image.TRANSPOSE)\n",
    "\n",
    "wsi = OpenSlide(preproc_conf.WSI_root_dir+'BRACS_773.svs')\n",
    "print(wsi.level_dimensions[2])\n",
    "img = np.array( wsi.read_region((0,0), 2, wsi.level_dimensions[2]).convert('RGB') )\n",
    "\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot polygons with colors based on the string labels\n",
    "for p in range(len(polygons_all[384])):\n",
    "    pol = polygons_all[384][p]\n",
    "    label = labels_all[384][p]\n",
    "    color = label_to_color[label]  # Get the color corresponding to the label from the colormap\n",
    "    plot_polygon_without_nodes(pol, ax, edgecolor=color)\n",
    "\n",
    "plt.savefig('save_bracs_slides_' + wsi.properties['aperio.Filename']+'.png', dpi=300)\n",
    "plt.savefig('save_bracs_slides_' + wsi.properties['aperio.Filename']+'.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_list[358], len(labels_all[358]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a020d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot a polygon without nodes\n",
    "def plot_polygon_without_nodes(polygon, ax, edgecolor):\n",
    "    x, y = polygon.exterior.xy\n",
    "    ax.add_patch(Polygon(np.c_[x, y], edgecolor=edgecolor, facecolor=edgecolor, linewidth=3, alpha=0.5))\n",
    "\n",
    "# Add a subplot\n",
    "fig = plt.figure(figsize=(20, 20))  # Adjust the width and height as desired\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# transposed_image = img_to_vis.transpose(Image.TRANSPOSE)\n",
    "wsi = OpenSlide(preproc_conf.WSI_root_dir+'BRACS_311.svs')\n",
    "print(wsi.level_dimensions[2])\n",
    "img = np.array( wsi.read_region((0,0), 2, wsi.level_dimensions[2]).convert('RGB') )\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot polygons with colors based on the string labels\n",
    "for p in range(len(polygons_all[358])):\n",
    "    pol = polygons_all[358][p]\n",
    "    label = labels_all[358][p]\n",
    "    color = label_to_color[label]  # Get the color corresponding to the label from the colormap\n",
    "    plot_polygon_without_nodes(pol, ax, edgecolor=color)\n",
    "\n",
    "plt.savefig('save_bracs_slides_' + wsi.properties['aperio.Filename']+'.png', dpi=300)\n",
    "plt.savefig('save_bracs_slides_' + wsi.properties['aperio.Filename']+'.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0635017c",
   "metadata": {},
   "source": [
    "### Read out reference patches for each class"
   ]
  },
  {
   "cell_type": "raw",
   "id": "327bc5dd",
   "metadata": {},
   "source": [
    "Cytomine coordinates for patches of classes:\n",
    "\n",
    "Normal:\n",
    "311: 60000, 46400\n",
    "\n",
    "PB:\n",
    "311: 60000, 50500\n",
    "\n",
    "UDH:\n",
    "773: 75600, 13200\n",
    "\n",
    "\n",
    "ADH:\n",
    "1911: 34000, 10000\n",
    "\n",
    "FEA:\n",
    "311: 60000, 32000 \n",
    "\n",
    "\n",
    "DCIS:\n",
    "773: 62000, 14000\n",
    "\n",
    "\n",
    "IC:\n",
    "773: 62000, 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eea71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal:\n",
    "wsi = OpenSlide(preproc_conf.WSI_root_dir+'BRACS_311.svs')\n",
    "x_wsi, y_wsi = wsi.level_dimensions[0] # get level0 coordinate bounds\n",
    "print(x_wsi, y_wsi)\n",
    "x_start = 60000\n",
    "print(x_start, 46400)\n",
    "y_start = np.abs( y_wsi - 46400 )\n",
    "print(x_start, y_start)\n",
    "x_width, y_height = 224*2**4, 224*2**4 # read out from level2\n",
    "print(x_width, y_height)\n",
    "img = np.array(wsi.read_region( ( x_start, y_start), 0, (x_width, y_height) ).convert('RGB') ) #.rotate(180)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e91886",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(ax, image, text, color):\n",
    "    ax.imshow(image)\n",
    "    ax.text(0.5, -0.1, text, transform=ax.transAxes, color=color, fontsize=50,\n",
    "            horizontalalignment='center', verticalalignment='center', weight=\"bold\")\n",
    "    ax.axis('off')\n",
    "\n",
    "# Load OpenSlide\n",
    "wsi = OpenSlide(preproc_conf.WSI_root_dir+'BRACS_311.svs')\n",
    "\n",
    "# Image dimensions\n",
    "x_width, y_height = 224 * 2 ** 4, 224 * 2 ** 4\n",
    "\n",
    "# List of image paths and corresponding offsets\n",
    "images_info = [\n",
    "    {'path': preproc_conf.WSI_root_dir+'BRACS_311.svs',\n",
    "     'offset': (60000, 46400), 'label': 'N', 'color': label_to_color['NORMAL'] },\n",
    "    {'path': preproc_conf.WSI_root_dir+'BRACS_311.svs',\n",
    "     'offset': (60000, 50500), 'label': 'PB', 'color': label_to_color['PATHOLOGICAL-BENIGN']},\n",
    "    {'path': preproc_conf.WSI_root_dir+'BRACS_773.svs',\n",
    "     'offset': (75600, 13200), 'label': 'UDH', 'color': label_to_color['UDH']},\n",
    "    {'path': preproc_conf.WSI_root_dir+'BRACS_311.svs',\n",
    "     'offset': (60000, 32000), 'label': 'FEA', 'color': label_to_color['FEA']},\n",
    "    {'path': preproc_conf.WSI_root_dir+'BRACS_1911.svs',\n",
    "     'offset': (34000, 10000), 'label': 'ADH', 'color': label_to_color['ADH']},\n",
    "    {'path': preproc_conf.WSI_root_dir+'BRACS_773.svs',\n",
    "     'offset': (62000, 14000), 'label': 'DCIS', 'color': label_to_color['DCIS']},\n",
    "    {'path': preproc_conf.WSI_root_dir+'BRACS_773.svs',\n",
    "     'offset': (62000, 25000), 'label': 'IC', 'color': label_to_color['INVASIVE-CARCINOMA']}\n",
    "]\n",
    "\n",
    "# Create subplots for 7 images\n",
    "fig, axes = plt.subplots(1, 7, figsize=(30, 12))\n",
    "\n",
    "# Plot each image\n",
    "for i, ax in enumerate(axes):\n",
    "    image_info = images_info[i]\n",
    "    img_path = image_info['path']\n",
    "    img_label = image_info['label']\n",
    "    x_start, y_start = image_info['offset']\n",
    "    color = image_info['color']\n",
    "    \n",
    "    wsi = OpenSlide(img_path)  # Load the specific image\n",
    "    img = np.array(wsi.read_region((x_start, wsi.level_dimensions[0][1] - y_start), 0, (x_width, y_height)).convert('RGB'))\n",
    "    \n",
    "    plot_image(ax, img, img_label, color)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('paper_figures/save_bracs_patches_7classes.png', dpi=300)\n",
    "plt.savefig('paper_figures/save_bracs_patches_7classes.svg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_start, y_start), x_width, y_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0f8a0",
   "metadata": {},
   "source": [
    "#### United figure"
   ]
  },
  {
   "cell_type": "raw",
   "id": "064fbe8f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Load OpenSlide\n",
    "wsi = OpenSlide(preproc_conf.WSI_root_dir+'BRACS_311.svs')\n",
    "\n",
    "# Create a colormap based on string labels\n",
    "label_to_color = create_color_map(np.concatenate(labels_all))\n",
    "\n",
    "# Set up the main figure\n",
    "fig, axes = plt.subplots(2, 1, figsize=(20, 20))  # 2 rows, 1 column\n",
    "\n",
    "# First row: Two big images\n",
    "ax_big1 = axes[0]\n",
    "ax_big2 = axes[1]\n",
    "\n",
    "# Load and plot first big image\n",
    "wsi1 = OpenSlide(preproc_conf.WSI_root_dir+'BRACS_773.svs')\n",
    "img1 = np.array(wsi1.read_region((0, 0), 2, wsi1.level_dimensions[2]).convert('RGB'))\n",
    "ax_big1.imshow(img1)\n",
    "ax_big1.axis('off')\n",
    "\n",
    "# Plot polygons with colors for first big image\n",
    "for p in range(len(polygons_all[384])):\n",
    "    pol = polygons_all[384][p]\n",
    "    label = labels_all[384][p]\n",
    "    color = label_to_color[label]\n",
    "    plot_polygon_without_nodes(pol, ax_big1, edgecolor=color)\n",
    "\n",
    "# Load and plot second big image\n",
    "wsi2 = OpenSlide(preproc_conf.WSI_root_dir+'BRACS_311.svs')\n",
    "img2 = np.array(wsi2.read_region((0, 0), 2, wsi2.level_dimensions[2]).convert('RGB'))\n",
    "ax_big2.imshow(img2)\n",
    "ax_big2.axis('off')\n",
    "\n",
    "# Plot polygons with colors for second big image\n",
    "for p in range(len(polygons_all[358])):\n",
    "    pol = polygons_all[358][p]\n",
    "    label = labels_all[358][p]\n",
    "    color = label_to_color[label]\n",
    "    plot_polygon_without_nodes(pol, ax_big2, edgecolor=color)\n",
    "\n",
    "for i, ax in enumerate(axes[2:]):\n",
    "    image_info = images_info[i]\n",
    "    img_path = image_info['path']\n",
    "    img_label = image_info['label']\n",
    "    x_start, y_start = image_info['offset']\n",
    "    color = image_info['color']\n",
    "    \n",
    "    wsi = OpenSlide(img_path)\n",
    "    img = np.array(wsi.read_region((x_start, wsi.level_dimensions[0][1] - y_start), 0, (x_width, y_height)).convert('RGB'))\n",
    "    \n",
    "    plot_image(ax, img, img_label, color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5406fc85",
   "metadata": {},
   "source": [
    "#### PLOT IDEA into paper:\n",
    "\n",
    "- extract few of these images with and without stainnorm\n",
    "- put the polygons of the extracted patches as grid into these plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b9daa1",
   "metadata": {},
   "source": [
    "### Load all slides with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_dir = os.path.join(preproc_conf.WSI_root_dir+'BRACS_WSI/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(preproc_conf.img_dir_lvl4)\n",
    "slide_list = np.array(sorted([j for j in os.listdir(data_dir) if '_level4.npy' in j]))\n",
    "slide_list[:5], slide_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5400757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slide_file_path(slide_id):\n",
    "    #slide_fp = os.path.join(data_dir,'*', '*', '*', f'{slide_id}.svs')\n",
    "    slide_fp = os.path.join(data_dir, f'{slide_id}_level4.npy')\n",
    "    return glob.glob(slide_fp)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d046acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_slide_file_path( annotation_list[0].strip('.geojson') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b2cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_filename = data_dir+annotation_list[0].split('.geojson')[0]+'_level4.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e028bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_annots_with_patches( patch_polygons, annot_polygons ):\n",
    "    # Populate R-tree index with bounds of grid cells\n",
    "    idx = index.Index()\n",
    "\n",
    "    for pos, cell in enumerate(annot_polygons):\n",
    "\n",
    "        # assuming cell is a shapely object\n",
    "        idx.insert(pos, cell.bounds)\n",
    "\n",
    "    # Loop through each Shapely polygon\n",
    "    intersections_list_area = []\n",
    "    intersections_list = []\n",
    "\n",
    "    for patch in patch_polygons:\n",
    "        # Merge cells that have overlapping bounding boxes\n",
    "        merged_region = unary_union([annot_polygons[pos] for pos in idx.intersection(patch.bounds)])\n",
    "        # Now do actual intersection\n",
    "        intersections_list_area.append(patch.intersection(merged_region).area)\n",
    "        intersections_list.append(patch.intersection(merged_region))\n",
    "    \n",
    "    return intersections_list, intersections_list_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4adae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intersect_annots_with_patches_notree( patch_polygons, annot_polygons ):\n",
    "    # merge all annotation polygons into one multipolygon\n",
    "    merged_region = unary_union(annot_polygons)\n",
    "    \n",
    "    intersections_list_area = []\n",
    "    intersections_list = []\n",
    "    intersection_all = []\n",
    "\n",
    "    # Loop through each patch given as shapely polygon and check if there is overlap\n",
    "    for patch in patch_polygons:\n",
    "        # No overlap means invalid value -> nan (need to handle it)\n",
    "        try:\n",
    "            print(patch)\n",
    "            intersections_list_area.append(patch.intersection(merged_region).area)\n",
    "            intersections_list.append(patch.intersection(merged_region))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return intersections_list, intersections_list_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_all[100][0].intersection( unary_union( polygons_all[100] ) )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab33dbdb-4da7-4504-a182-df0ced6cfec8",
   "metadata": {},
   "source": [
    "container_all = []\n",
    "container_labels_all = []\n",
    "for n in tqdm( range( len(annotation_list) ) ):\n",
    "    current_filename = get_slide_file_path( annotation_list[n].strip('.geojson') )\n",
    "    #print(current_filename)\n",
    "    current_img_np = np.load(current_filename)\n",
    "    #print(current_img_np.shape)\n",
    "    current_label = np.array(labels_all[n])\n",
    "    current_annots = np.array(polygons_all[n])\n",
    "    current_xdim = current_img_np.shape[1]\n",
    "    current_ydim = current_img_np.shape[0]\n",
    "    #print(current_xdim, current_ydim, current_annots)\n",
    "\n",
    "    # generate all patches based on slide level dimensions\n",
    "    grid_cells_all = []\n",
    "    grid_cells_all_np = []\n",
    "    for x in range(0, current_xdim//224*224, 224):\n",
    "        for y in range(0, current_ydim//224*224, 224):\n",
    "            grid_cells_all.append(shapely.geometry.box(x, y, x+224, y+224))\n",
    "            grid_cells_all_np.append(np.array([x, y]))\n",
    "            \n",
    "    grid_cells_all_np = np.array(grid_cells_all_np)\n",
    "    \n",
    "    # do this for all types of annotation present in the current slide\n",
    "    current_uqs = np.unique(current_label)\n",
    "    \n",
    "    #container_all = []\n",
    "    #container_labels_all = []\n",
    "    for u in range( current_uqs.shape[0] ):\n",
    "        # logical filter for current annotation\n",
    "        filt_uq = current_label == current_uqs[u]\n",
    "        #print(current_label, current_uqs[u], filt_uq.sum())\n",
    "        \n",
    "        _, intersections_list_area = intersect_annots_with_patches( grid_cells_all, current_annots[filt_uq] )\n",
    "        \n",
    "        topleft_read_from = grid_cells_all_np[np.nonzero(intersections_list_area)[0]]\n",
    "        #topleft_read_from = grid_cells_all_np[ np.array(intersections_list_area) > 0 ] # at least 20% overlap (224/5)**2\n",
    "        #if len(topleft_read_from) == 0:\n",
    "        #print('numread:', topleft_read_from, filt_uq.sum())\n",
    "        \n",
    "        container = np.empty( (topleft_read_from.shape[0], 224, 224, 3), dtype=np.uint8 )\n",
    "        container_labels = np.repeat(current_uqs[u], container.shape[0])\n",
    "        #print(n ,'into:', current_uqs[u], container_labels, container.shape)\n",
    "        for p in range(topleft_read_from.shape[0]):\n",
    "            #print('ppp', p, topleft_read_from.shape[0])\n",
    "            #print(topleft_read_from[p,0], topleft_read_from[p,0]+224, topleft_read_from[p,1], topleft_read_from[p,1]+224)\n",
    "            container[p] = current_img_np[ topleft_read_from[p,1]:topleft_read_from[p,1]+224, \n",
    "                                           topleft_read_from[p,0]:topleft_read_from[p,0]+224, :]\n",
    "        container_all.append(container)\n",
    "        container_labels_all.append(container_labels)\n",
    "        \n",
    "        #print( current_uqs[u], grid_cells_all_np[np.nonzero(np.array(intersections_list_area))[0]] )\n",
    "\n",
    "container_all = np.concatenate(container_all)\n",
    "container_labels_all = np.concatenate(container_labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af457aec-9387-4939-8ee4-64ee3ecd5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patches(annotation_list_current_set, labels_current_set, polygons_current_set):\n",
    "    container_all = []\n",
    "    container_labels_all = []\n",
    "\n",
    "    for n in tqdm( range( len(annotation_list_current_set) ) ):\n",
    "        current_filename = get_slide_file_path( annotation_list_current_set[n].strip('.geojson') )\n",
    "        #print(current_filename)\n",
    "        current_img_np = np.load(current_filename)\n",
    "        #print(current_img_np.shape)\n",
    "        current_label = np.array(labels_current_set[n])\n",
    "        current_annots = np.array(polygons_current_set[n])\n",
    "        current_xdim = current_img_np.shape[1]\n",
    "        current_ydim = current_img_np.shape[0]\n",
    "        #print(current_xdim, current_ydim, current_annots)\n",
    "    \n",
    "        # generate all patches based on slide level dimensions\n",
    "        grid_cells_all = []\n",
    "        grid_cells_all_np = []\n",
    "        for x in range(0, current_xdim//224*224, 224):\n",
    "            for y in range(0, current_ydim//224*224, 224):\n",
    "                grid_cells_all.append(shapely.geometry.box(x, y, x+224, y+224))\n",
    "                grid_cells_all_np.append(np.array([x, y]))\n",
    "                \n",
    "        grid_cells_all_np = np.array(grid_cells_all_np)\n",
    "        \n",
    "        # do this for all types of annotation present in the current slide\n",
    "        current_uqs = np.unique(current_label)\n",
    "        \n",
    "        #container_all = []\n",
    "        #container_labels_all = []\n",
    "        for u in range( current_uqs.shape[0] ):\n",
    "            # logical filter for current annotation\n",
    "            filt_uq = current_label == current_uqs[u]\n",
    "            #print(current_label, current_uqs[u], filt_uq.sum())\n",
    "            \n",
    "            _, intersections_list_area = intersect_annots_with_patches( grid_cells_all, current_annots[filt_uq] )\n",
    "            \n",
    "            topleft_read_from = grid_cells_all_np[np.nonzero(intersections_list_area)[0]]\n",
    "            #topleft_read_from = grid_cells_all_np[ np.array(intersections_list_area) > 0 ] # at least 20% overlap (224/5)**2\n",
    "            #if len(topleft_read_from) == 0:\n",
    "            #print('numread:', topleft_read_from, filt_uq.sum())\n",
    "            \n",
    "            container = np.empty( (topleft_read_from.shape[0], 224, 224, 3), dtype=np.uint8 )\n",
    "            container_labels = np.repeat(current_uqs[u], container.shape[0])\n",
    "            #print(n ,'into:', current_uqs[u], container_labels, container.shape)\n",
    "            for p in range(topleft_read_from.shape[0]):\n",
    "                #print('ppp', p, topleft_read_from.shape[0])\n",
    "                #print(topleft_read_from[p,0], topleft_read_from[p,0]+224, topleft_read_from[p,1], topleft_read_from[p,1]+224)\n",
    "                container[p] = current_img_np[ topleft_read_from[p,1]:topleft_read_from[p,1]+224, \n",
    "                                               topleft_read_from[p,0]:topleft_read_from[p,0]+224, :]\n",
    "            container_all.append(container)\n",
    "            container_labels_all.append(container_labels)\n",
    "            \n",
    "            #print( current_uqs[u], grid_cells_all_np[np.nonzero(np.array(intersections_list_area))[0]] )\n",
    "    \n",
    "    container_all = np.concatenate(container_all)\n",
    "    container_labels_all = np.concatenate(container_labels_all)\n",
    "    \n",
    "    return container_all, container_labels_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9617bb-1829-494f-a851-ff70521e0b61",
   "metadata": {},
   "source": [
    "### Do extraction and stratification according to BRACS paper and their splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7333c2a-6c85-4c58-a3d2-f2567d7cbe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_training, container_training_labels = generate_patches(annotation_list_training, labels_training, polygons_training )\n",
    "container_training.shape, container_training_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023cc7f-aeb0-4817-90a6-92b65225a35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_validation, container_validation_labels = generate_patches(annotation_list_validation, labels_validation, polygons_validation)\n",
    "container_validation.shape, container_validation_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ea52b-4b97-4da5-9177-a9d3f4037998",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_test, container_test_labels = generate_patches(annotation_list_test, labels_test, polygons_test)\n",
    "container_test.shape, container_test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de9000-5747-48ad-9358-81103acc6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# was when there was leakage at patient 67: 6099 + 606 + 1058\n",
    "6067 + 638 + 1058"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97d28cb3-5bd9-4632-b696-54cd8876bac2",
   "metadata": {},
   "source": [
    "container_all.shape # old approach merged together all: (7763, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884557c",
   "metadata": {},
   "source": [
    "### Save nonorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380bb8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = preproc_conf.img_dir_lvl4\n",
    "base_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b97c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.save(base_folder+'bracs_level4_regions_224_training_data.npy', container_training)\n",
    "np.save(base_folder+'bracs_level4_regions_224_training_label.npy', container_training_labels)\n",
    "\n",
    "np.save(base_folder+'bracs_level4_regions_224_validation_data.npy', container_validation)\n",
    "np.save(base_folder+'bracs_level4_regions_224_validation_label.npy', container_validation_labels)\n",
    "\n",
    "np.save(base_folder+'bracs_level4_regions_224_test_data.npy', container_test)\n",
    "np.save(base_folder+'bracs_level4_regions_224_test_label.npy', container_test_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01027c1b-1869-4564-8ebc-6ea9a87c91f5",
   "metadata": {},
   "source": [
    "It was before:\n",
    "\n",
    "Counter( container_labels_all )\n",
    "\n",
    "Counter({'INVASIVE-CARCINOMA': 1900,\n",
    "         'PATHOLOGICAL-BENIGN': 1733,\n",
    "         'DCIS': 1335,\n",
    "         'NORMAL': 863,\n",
    "         'UDH': 759,\n",
    "         'ADH': 598,\n",
    "         'FEA': 575})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2fdd5-fa80-43ad-aeeb-c19efa903e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_info, validation_info, test_info = Counter( container_training_labels ), Counter( container_validation_labels ), Counter( container_test_labels )\n",
    "training_info + validation_info + test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847447d0-8c66-438d-8452-97134039979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter( container_training_labels ), Counter( container_validation_labels ), Counter( container_test_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d515c3-ed8d-4ea9-b4c0-3f56bb588f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total for each set\n",
    "total_training = sum(Counter( container_training_labels ).values())\n",
    "total_validation = sum(Counter( container_validation_labels ).values())\n",
    "total_test = sum(Counter( container_test_labels ).values())\n",
    "\n",
    "# Calculate ratios\n",
    "ratios_training = {label: count / total_training for label, count in Counter( container_training_labels ).items()}\n",
    "ratios_validation = {label: count / total_validation for label, count in Counter( container_validation_labels ).items()}\n",
    "ratios_test = {label: count / total_test for label, count in Counter( container_test_labels ).items()}\n",
    "\n",
    "# Display ratios\n",
    "print(\"Training Set Ratios:\")\n",
    "for label, ratio in ratios_training.items():\n",
    "    print(f\"{label}: {ratio * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nValidation Set Ratios:\")\n",
    "for label, ratio in ratios_validation.items():\n",
    "    print(f\"{label}: {ratio * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nTest Set Ratios:\")\n",
    "for label, ratio in ratios_test.items():\n",
    "    print(f\"{label}: {ratio * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e07c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( container_training[100]), container_training_labels[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(container_training[1000]), container_training_labels[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(container_training[2000]), container_training_labels[2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0aca5",
   "metadata": {},
   "source": [
    "### Save Macenko norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6ea29",
   "metadata": {},
   "source": [
    "#### this comes from nightingale "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c311bb4",
   "metadata": {},
   "source": [
    "reference_image = np.load('reference_image_patches_level4_224_224_3_nightingale.npy')\n",
    "stain_normalizer = stainnorm.MacenkoNormalizer()\n",
    "stain_normalizer.fit(reference_image)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8722371f",
   "metadata": {},
   "source": [
    "container_all_normed = np.zeros(container_all.shape, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fc72343",
   "metadata": {},
   "source": [
    "for c in tqdm( range(container_all.shape[0]) ):\n",
    "    container_all_normed[c] = stain_normalizer.transform(container_all[c].copy())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9ebb57f",
   "metadata": {},
   "source": [
    "# Create a figure and axis objects\n",
    "fig, ax = plt.subplots(3, 2, figsize=(6, 9))\n",
    "\n",
    "# Plot the image on the corresponding axis\n",
    "ax[0, 0].imshow(container_all[10])\n",
    "ax[1, 0].imshow(container_all[1000])\n",
    "ax[2, 0].imshow(container_all[2000])\n",
    "ax[0, 1].imshow(container_all_normed[10])\n",
    "ax[1, 1].imshow(container_all_normed[1000])\n",
    "ax[2, 1].imshow(container_all_normed[2000])\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        ax[i, j].axis('off')  # Turn off axis labels\n",
    "        # Add a line with the specified linestyle\n",
    "        #ax[i, j].plot([0, 1], [0, 1], color='red', linestyle=lines[i*2+j])\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3aefe19f",
   "metadata": {},
   "source": [
    "np.save(base_folder+'bracs_level4_regions_224_data_macenkonorm.npy', container_all_normed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5581b5",
   "metadata": {},
   "source": [
    "#### norm on bracs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58cc2be-8576-4ac2-8be9-0ca041ad0ba9",
   "metadata": {},
   "source": [
    "#### Norm only on bracs training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92bafc9-bd7a-4d58-a2bf-349e4509c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_array_slides = np.zeros( (container_training.shape[0], 6), dtype=np.uint8)\n",
    "\n",
    "# iterate over all images in training set\n",
    "for i in tqdm(range(container_training.shape[0])):\n",
    "    img_curr = container_training[i]\n",
    "    \n",
    "    b, g, r = cv2.split(img_curr)\n",
    "    mean_b, mean_g, mean_r = np.mean(b), np.mean(g), np.mean(r)\n",
    "    std_b, std_g, std_r = np.std(b), np.std(g), np.std(r)\n",
    "\n",
    "    stats_array_slides[i, 0] = mean_b\n",
    "    stats_array_slides[i, 1] = mean_g\n",
    "    stats_array_slides[i, 2] = mean_r\n",
    "    stats_array_slides[i, 3] = std_b\n",
    "    stats_array_slides[i, 4] = std_g\n",
    "    stats_array_slides[i, 5] = std_r\n",
    "    \n",
    "stats_array_all = stats_array_slides\n",
    "#np.save('stats_array_all_reference_image_patches_level4_224_224_3.npy', stats_array_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e8b6d-ddc4-414c-9333-c0b14c7788ef",
   "metadata": {},
   "source": [
    "#### Norm on bracs training and validation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5266ae3-7f85-403a-be3d-7176983d7489",
   "metadata": {},
   "source": [
    "stats_array_slides = np.zeros( (container_training.shape[0]+container_validation.shape[0], 6), dtype=np.uint8)\n",
    "\n",
    "# iterate over all images in training set\n",
    "for i in tqdm(range(container_training.shape[0])):\n",
    "    img_curr = container_training[i]\n",
    "    \n",
    "    b, g, r = cv2.split(img_curr)\n",
    "    mean_b, mean_g, mean_r = np.mean(b), np.mean(g), np.mean(r)\n",
    "    std_b, std_g, std_r = np.std(b), np.std(g), np.std(r)\n",
    "\n",
    "    stats_array_slides[i, 0] = mean_b\n",
    "    stats_array_slides[i, 1] = mean_g\n",
    "    stats_array_slides[i, 2] = mean_r\n",
    "    stats_array_slides[i, 3] = std_b\n",
    "    stats_array_slides[i, 4] = std_g\n",
    "    stats_array_slides[i, 5] = std_r\n",
    "    #print(i)\n",
    "\n",
    "# iterate over all images in validation set\n",
    "for e, i in tqdm( enumerate( range( container_training.shape[0], container_training.shape[0]+container_validation.shape[0] ) )):\n",
    "    img_curr = container_validation[e]\n",
    "    \n",
    "    b, g, r = cv2.split(img_curr)\n",
    "    mean_b, mean_g, mean_r = np.mean(b), np.mean(g), np.mean(r)\n",
    "    std_b, std_g, std_r = np.std(b), np.std(g), np.std(r)\n",
    "\n",
    "    stats_array_slides[i, 0] = mean_b\n",
    "    stats_array_slides[i, 1] = mean_g\n",
    "    stats_array_slides[i, 2] = mean_r\n",
    "    stats_array_slides[i, 3] = std_b\n",
    "    stats_array_slides[i, 4] = std_g\n",
    "    stats_array_slides[i, 5] = std_r\n",
    "    #print(e, i)\n",
    "    \n",
    "stats_array_all = stats_array_slides\n",
    "#np.save('stats_array_all_reference_image_patches_level4_224_224_3.npy', stats_array_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db447bcd-f4f6-4310-b5a2-7a1c03d4e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_array_all[:5], stats_array_all[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51acfbf0-6594-41ea-aa4f-8dcd86bebf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_array_all.mean(0) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_values = np.median(stats_array_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746239f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.linalg.norm(stats_array_all - median_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8dedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image_idx = np.argmin(distances)\n",
    "reference_image_idx # this index falls into first part, into the training container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image = container_training[reference_image_idx]\n",
    "container_training_labels[reference_image_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5acb2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(reference_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('reference_image_patches_level4_224_224_3_bracs.npy', reference_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7c3c9",
   "metadata": {},
   "source": [
    "#### this comes from bracs training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image = np.load('reference_image_patches_level4_224_224_3_bracs.npy')\n",
    "stain_normalizer = stainnorm.MacenkoNormalizer()\n",
    "stain_normalizer.fit(reference_image)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f0e067d-1e4d-437b-a766-6296ebfaeec8",
   "metadata": {},
   "source": [
    "container_all_normed = np.zeros(container_all.shape, dtype=np.uint8)\n",
    "\n",
    "for c in tqdm( range(container_all.shape[0]) ):\n",
    "    container_all_normed[c] = stain_normalizer.transform(container_all[c].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63344640-0fc0-4da1-b092-16d75e406c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_training_normed = np.zeros(container_training.shape, dtype=np.uint8)\n",
    "\n",
    "for c in tqdm( range(container_training.shape[0]) ):\n",
    "    container_training_normed[c] = stain_normalizer.transform(container_training[c].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef708f-b751-43b2-998a-df75cf3980dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_validation_normed = np.zeros(container_validation.shape, dtype=np.uint8)\n",
    "\n",
    "for c in tqdm( range(container_validation.shape[0]) ):\n",
    "    container_validation_normed[c] = stain_normalizer.transform(container_validation[c].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e967f4a-a402-4b46-8814-795ae60c5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_test_normed = np.zeros(container_test.shape, dtype=np.uint8)\n",
    "\n",
    "for c in tqdm( range(container_test.shape[0]) ):\n",
    "    container_test_normed[c] = stain_normalizer.transform(container_test[c].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3295b84c-7d05-497a-acd7-78be686890ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#was before: np.save(base_folder+'bracs_level4_regions_224_data_macenkonorm_bracs.npy', container_all_normed)\n",
    "\n",
    "np.save(base_folder+'bracs_level4_regions_224_training_data_macenkonorm_bracs.npy', container_training_normed)\n",
    "np.save(base_folder+'bracs_level4_regions_224_validation_data_macenkonorm_bracs.npy', container_validation_normed)\n",
    "np.save(base_folder+'bracs_level4_regions_224_test_data_macenkonorm_bracs.npy', container_test_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b5540-2578-4b82-9b43-12f570c04737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8859590-56b7-4de3-a157-2812f1057faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis objects\n",
    "fig, ax = plt.subplots(3, 2, figsize=(6, 9))\n",
    "\n",
    "# Plot the image on the corresponding axis\n",
    "ax[0, 0].imshow(container_training[11])\n",
    "ax[1, 0].imshow(container_training[111])\n",
    "ax[2, 0].imshow(container_training[205])\n",
    "ax[0, 1].imshow(container_training_normed[11])\n",
    "ax[1, 1].imshow(container_training_normed[111])\n",
    "ax[2, 1].imshow(container_training_normed[205])\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        ax[i, j].axis('off')  # Turn off axis labels\n",
    "        # Add a line with the specified linestyle\n",
    "        #ax[i, j].plot([0, 1], [0, 1], color='red', linestyle=lines[i*2+j])\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d541e8-0635-4b7c-b4f5-02e064c95d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d990164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis objects\n",
    "fig, ax = plt.subplots(3, 2, figsize=(6, 9))\n",
    "\n",
    "# Plot the image on the corresponding axis\n",
    "ax[0, 0].imshow(container_test[11])\n",
    "ax[1, 0].imshow(container_test[105])\n",
    "ax[2, 0].imshow(container_test[205])\n",
    "ax[0, 1].imshow(container_test_normed[11])\n",
    "ax[1, 1].imshow(container_test_normed[105])\n",
    "ax[2, 1].imshow(container_test_normed[205])\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        ax[i, j].axis('off')  # Turn off axis labels\n",
    "        # Add a line with the specified linestyle\n",
    "        #ax[i, j].plot([0, 1], [0, 1], color='red', linestyle=lines[i*2+j])\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a9cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1788f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nonormed_npy_for_testing = np.load(base_folder+'bracs_level4_regions_224_training_data.npy')\n",
    "train_normed_npy_for_testing = np.load(base_folder+'bracs_level4_regions_224_training_data_macenkonorm_bracs.npy')\n",
    "train_nonormed_npy_for_testing.shape, train_normed_npy_for_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b89208-8508-4e38-9b8f-12bcc8ceb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis objects\n",
    "fig, ax = plt.subplots(3, 2, figsize=(6, 9))\n",
    "\n",
    "# Plot the image on the corresponding axis\n",
    "ax[0, 0].imshow(train_nonormed_npy_for_testing[11])\n",
    "ax[1, 0].imshow(train_nonormed_npy_for_testing[105])\n",
    "ax[2, 0].imshow(train_nonormed_npy_for_testing[205])\n",
    "ax[0, 1].imshow(train_normed_npy_for_testing[11])\n",
    "ax[1, 1].imshow(train_normed_npy_for_testing[105])\n",
    "ax[2, 1].imshow(train_normed_npy_for_testing[205])\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        ax[i, j].axis('off')  # Turn off axis labels\n",
    "        # Add a line with the specified linestyle\n",
    "        #ax[i, j].plot([0, 1], [0, 1], color='red', linestyle=lines[i*2+j])\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed8366-6de2-4110-bde8-b730ac809c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist( (train_nonormed_npy_for_testing[11]-train_normed_npy_for_testing[11]).flatten() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19c7af-9e2c-4cf9-9792-04ae3eea96f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bd21c-f001-4a42-89c9-f51055dcdef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da5c0a2-2543-4d45-baea-b4e070a31e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
