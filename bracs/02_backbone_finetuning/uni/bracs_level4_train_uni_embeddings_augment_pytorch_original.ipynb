{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6110b5",
   "metadata": {},
   "source": [
    "### Data source: https://www.bracs.icar.cnr.it/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd0608",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import timm\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "# Load config\n",
    "preproc_conf = OmegaConf.load(\"../conf/preproc.yaml\")\n",
    "preproc_conf = preproc_conf['classic_mil_on_embeddings_bag']['bracs_224_224_patches']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c4c9b",
   "metadata": {},
   "source": [
    "### Locate annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = preproc_conf.img_dir_lvl4\n",
    "parent_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992d6e7",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48778317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## HERE CHOOSE NO NORM OR MACENKO NORM:\n",
    "#data = np.load( parent_folder+'bracs_level4_regions_224_data.npy')\n",
    "data = np.load( parent_folder+'bracs_level4_regions_224_data_macenkonorm_bracs.npy')\n",
    "\n",
    "## load this to be able to gen confusion matrices:\n",
    "data_macenko = np.load( parent_folder+'bracs_level4_regions_224_data_macenkonorm_bracs.npy')\n",
    "\n",
    "label = np.load( parent_folder+'bracs_level4_regions_224_label.npy')\n",
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f898cfa",
   "metadata": {},
   "source": [
    "### Preprocess label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13173567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary encode\n",
    "lb = LabelEncoder()\n",
    "#lb = LabelBinarizer()\n",
    "lb.fit(label)\n",
    "label_oh = lb.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca040cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f92d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(label_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730e153",
   "metadata": {},
   "source": [
    "### Create balanced data loader -> balanced folds with subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_biopsy_subset(labels, minority_class_ratio=0.2, rnd_seed=38):\n",
    "    # set random seed as given\n",
    "    np.random.seed(rnd_seed)\n",
    "    \n",
    "    # collect selected biopsies that will be in the balanced subset\n",
    "    test_local_idx = []\n",
    "    \n",
    "    # get current class occurences for biopsy\n",
    "    class_occurence = np.array(list(dict( Counter(labels) ).values()))[ np.argsort(list(dict( Counter(labels) ).keys()))]\n",
    "    #print(class_occurence)\n",
    "    \n",
    "    # calc class weights\n",
    "    class_weights = ( class_occurence / class_occurence.sum() ).astype(np.float32)\n",
    "    class_weights_dict = dict( zip( np.arange(class_weights.shape[0]), class_weights ))\n",
    "    #print(class_weights_dict)\n",
    "    \n",
    "    # how many of biopsies to include in the balanced subset\n",
    "    nr_class_test = int(labels.shape[0]*np.min(class_weights)*minority_class_ratio)\n",
    "\n",
    "    # collect biopsy indices for the balanced subset\n",
    "    for s in np.unique(labels): #loop over labelss\n",
    "        s_idx = np.arange(labels.shape[0])[labels == s]\n",
    "        rnd_idx = np.random.permutation(s_idx.shape[0])\n",
    "        test_local_idx.append(s_idx[rnd_idx[:nr_class_test]])\n",
    "\n",
    "    # aggregate all the balanced subset's indices\n",
    "    test_idx = np.concatenate(test_local_idx)\n",
    "    \n",
    "    # other indices not in balanced set will be the rest\n",
    "    train_idx = np.arange(labels.shape[0])[~np.in1d(np.arange(labels.shape[0]), test_idx)]\n",
    "    \n",
    "    return train_idx, test_idx#, label_remaining[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab04358",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_idx, val_idx = create_balanced_biopsy_subset(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = data[val_idx]\n",
    "y_val = label[val_idx]\n",
    "y_val = lb.transform(y_val)\n",
    "\n",
    "X_remaining = data[remaining_idx]\n",
    "y_remaining = label[remaining_idx]\n",
    "y_remaining = lb.transform(y_remaining)\n",
    "\n",
    "X_val.shape, y_val.shape, X_remaining.shape, y_remaining.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337804b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_macenko = data_macenko[val_idx]\n",
    "X_remaining_macenko = data_macenko[remaining_idx]\n",
    "\n",
    "X_val = data[val_idx]\n",
    "X_remaining = data[remaining_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4753cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_back_balanced_training_fold( X_current, y_current,\n",
    "                                      minority_class_ratio=0.25, rnd_seed=12 ):\n",
    "    \n",
    "    _, test_idx, = create_balanced_biopsy_subset(y_current,\n",
    "                                                 minority_class_ratio,\n",
    "                                                 rnd_seed)\n",
    "    X_train_balanced = X_current[test_idx]\n",
    "    y_train_balanced = y_current[test_idx]\n",
    "    #y_train_balanced_oh = lb.transform(y_train_balanced)\n",
    "    #print( X_train_balanced.shape, y_train_balanced_oh.shape )\n",
    "    \n",
    "    return X_train_balanced, y_train_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = give_back_balanced_training_fold(X_remaining, y_remaining, rnd_seed=15)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affec6a3",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c2259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectionsDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 num_classes, \n",
    "                 transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {'image': image,\n",
    "                'label': label\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pytorch/pytorch/issues/7359\n",
    "class BalancedSampler(Sampler):\n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 num_classes, \n",
    "                 transform=None,\n",
    "                 rand_seed=12):\n",
    "        self.batch_size = batch_size\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.num_classes = num_classes\n",
    "        self.rand_seed = rand_seed\n",
    "        \n",
    "\n",
    "        \n",
    "    def give_back_balanced_training_fold(self, X_current, y_current, minority_class_ratio, rand_seed):\n",
    "        _, test_idx = create_balanced_biopsy_subset(y_current, minority_class_ratio, rand_seed)\n",
    "        \n",
    "        return test_idx\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        test_idx = self.give_back_balanced_training_fold(self.data, self.labels, minority_class_ratio=0.25, rand_seed=self.rand_seed)\n",
    "        \n",
    "        return len(test_idx) #3220\n",
    "\n",
    "    def __iter__(self):\n",
    "        test_idx = self.give_back_balanced_training_fold(self.data, self.labels, minority_class_ratio=0.25, rand_seed=self.rand_seed)\n",
    "        \n",
    "        random.shuffle(test_idx)\n",
    "        num_batches = len(test_idx) // self.batch_size - 1 #99\n",
    "        \n",
    "        n=0\n",
    "        while num_batches > 0:\n",
    "            \n",
    "            sampled = test_idx[n*32:(n+1)*32]\n",
    "                \n",
    "            yield sampled #(32, 3, 224, 224)\n",
    "            num_batches -=1\n",
    "            n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchBalancedSampler(Sampler):\n",
    "\n",
    "    def __init__(self, sampler, batch_size):\n",
    "        self.sampler = sampler\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _, idx in enumerate(iter(self.sampler)): #99\n",
    "            batch = idx\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sampler) // self.batch_size - 1 #99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc7e9f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d8e563-2a4c-4eca-8524-b8cc6d0009a1",
   "metadata": {},
   "source": [
    "#### frozen backbone"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa873597-2931-41ff-876d-a374e99013ee",
   "metadata": {},
   "source": [
    "# Load UNI model\n",
    "model = timm.create_model(\n",
    "    \"vit_large_patch16_224\", img_size=224, patch_size=16, init_values=1e-5, num_classes=0\n",
    ")\n",
    "model.load_state_dict(torch.load(preproc_conf.uni_embedder_weights, map_location=\"cpu\"), strict=True)\n",
    "# Modify head to match this task\n",
    "model.head = nn.Linear(in_features=1024, out_features=7)\n",
    "\n",
    "\"\"\"\n",
    "model.head = nn.Sequential(\n",
    "    nn.Linear(in_features=1024, out_features=128),\n",
    "    nn.ReLU(),    \n",
    "    nn.Linear(in_features=128, out_features=7))\n",
    "\"\"\"\n",
    "\n",
    "# Freeze all parameters in the model except for those in the head\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the head parameters\n",
    "for param in model.head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "device = torch.device(f\"cuda:{0}\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b7027b-d10b-42be-ac43-af917404f389",
   "metadata": {},
   "source": [
    "#### very small LR for backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200df147-9ae1-4d26-8551-0e0e92393721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNI model\n",
    "model = timm.create_model(\n",
    "    \"vit_large_patch16_224\", img_size=224, patch_size=16, init_values=1e-5, num_classes=0\n",
    ")\n",
    "model.load_state_dict(torch.load(preproc_conf.uni_embedder_weights, map_location=\"cpu\"), strict=True)\n",
    "# Modify head to match this task\n",
    "#model.head = nn.Linear(in_features=1024, out_features=7)\n",
    "\n",
    "model.head = nn.Sequential(\n",
    "    nn.Linear(in_features=1024, out_features=128),\n",
    "    nn.ReLU(),    \n",
    "    nn.Linear(in_features=128, out_features=7))\n",
    "\n",
    "# Define two sets of parameters: one for the backbone and one for the head\n",
    "backbone_params = [param for name, param in model.named_parameters() if 'head' not in name]\n",
    "head_params = model.head.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d95085",
   "metadata": {},
   "source": [
    "## Traning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c497f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = 'weights_train_uni_smallLRbackbone_complexhead_level4_macenko_bracs_100epochs/'\n",
    "\n",
    "os.makedirs(weights_folder, exist_ok=True)\n",
    "\n",
    "def train_model(model,\n",
    "                device,\n",
    "                transform,\n",
    "                optimizer, \n",
    "                scheduler, \n",
    "                num_epochs):\n",
    "    \n",
    "    history = {}\n",
    "    history_train_loss = []\n",
    "    history_train_acc = []\n",
    "    history_val_loss = []\n",
    "    history_val_acc = []\n",
    "    \n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    train_dataset = CollectionsDataset(data=X_remaining,\n",
    "                                       labels=y_remaining,\n",
    "                                       num_classes=NUM_CLASSES,\n",
    "                                       transform=transform)\n",
    "    \n",
    "    # VAL dataset\n",
    "    val_dataset = CollectionsDataset(data=X_val,\n",
    "                                     labels=y_val,\n",
    "                                     num_classes=NUM_CLASSES,\n",
    "                                     transform=transform)\n",
    "\n",
    "    # create the pytorch data loader\n",
    "    val_dataset_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     num_workers=4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # training loop wiht balanced folds\n",
    "    for epoch in range(0, num_epochs):\n",
    "        \n",
    "        sampler = BalancedSampler(\n",
    "                     batch_size=32,\n",
    "                     data=X_remaining,\n",
    "                     labels=y_remaining,\n",
    "                     num_classes=NUM_CLASSES, \n",
    "                     transform=None,\n",
    "                     rand_seed=int(epoch*1.5+3*epoch))\n",
    "\n",
    "        batch_sampler = BatchBalancedSampler(sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "        # create the pytorch data loader\n",
    "        train_dataset_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                           num_workers=4,\n",
    "                                                           batch_sampler=batch_sampler)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        \n",
    "\n",
    "        #scheduler.step()\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Iterate over data.\n",
    "        \n",
    "        \n",
    "        for bi, d in enumerate(train_dataset_loader):\n",
    "            \n",
    "            inputs = d[\"image\"]\n",
    "            labels = d[\"label\"]\n",
    "            inputs = inputs.to(device, dtype=torch.float, non_blocking=True)\n",
    "            labels = labels.to(device, dtype=torch.long,  non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            #acc metrics\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        checkpoint = { \n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            #'scheduler': scheduler\n",
    "        }\n",
    "            \n",
    "        epoch_loss = running_loss / (len(sampler) -52)\n",
    "        writer.add_scalar(\"Train CE Loss\", epoch_loss)\n",
    "        print('Train CE Loss: {:.4f}'.format(epoch_loss), f'----- Train Accuracy: {100 * correct // total} %')\n",
    "        \n",
    "        \n",
    "        history_train_loss.append(epoch_loss)\n",
    "        history_train_acc.append(100 * correct // total)\n",
    "        \n",
    "        \n",
    "        # VALIDATION\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        running_loss_val = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for bi, d in enumerate(val_dataset_loader):\n",
    "                inputs = d[\"image\"]\n",
    "                labels = d[\"label\"]\n",
    "                inputs = inputs.to(device, dtype=torch.float)\n",
    "                labels = labels.to(device, dtype=torch.long)\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = model(inputs)\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                \n",
    "                loss_val = criterion(outputs, labels)\n",
    "                \n",
    "                running_loss_val += loss_val.item() * inputs.size(0)\n",
    "                \n",
    "        epoch_loss_val = running_loss_val / X_val.shape[0]\n",
    "        print('Val CE Loss: {:.4f}'.format(epoch_loss_val), f'----- Val Accuracy: {100 * correct_val // total_val} %')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        history_val_loss.append(epoch_loss_val)\n",
    "        history_val_acc.append(100 * correct_val // total_val)\n",
    "        \n",
    "        if (100 * correct_val // total_val) > 59:\n",
    "            print(weights_folder+f'checkpoint_epoch_{epoch}'+\\\n",
    "                   '_{:.4f}'.format(epoch_loss_val)+f'_{100 * correct_val // total_val} %.pth')\n",
    "            torch.save(checkpoint, weights_folder+f'checkpoint_epoch_{epoch}'+\\\n",
    "                   '_{:.4f}'.format(epoch_loss_val)+f'CE_{100 * correct_val // total_val}_acc.pth')\n",
    "\n",
    "    history['train_loss'] = history_train_loss\n",
    "    history['train_acc'] = history_train_acc\n",
    "    history['val_loss'] = history_val_loss\n",
    "    history['val_acc'] = history_val_acc\n",
    "    \n",
    "    writer.flush()\n",
    "        \n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc4600c",
   "metadata": {},
   "source": [
    "## Transforms, augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96396a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_transform = transforms.Compose([transforms.ToTensor(), transforms.RandomResizedCrop(size=224, scale=(0.55,1))])\n",
    "\n",
    "dummy_transform2 = transforms.Compose([transforms.ToTensor(), transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)])\n",
    "\n",
    "dummy_transform3 = transforms.Compose([transforms.ToTensor(), transforms.RandomAdjustSharpness(sharpness_factor=3, p=0.5)])\n",
    "\n",
    "dummy_transform4 = transforms.Compose([transforms.ToTensor(), transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 3))])\n",
    "\n",
    "\n",
    "dummy_dataset = CollectionsDataset(data=X_remaining,\n",
    "                                       labels=y_remaining,\n",
    "                                       num_classes=7,\n",
    "                                       transform=dummy_transform4)\n",
    "\n",
    "plt.imshow(np.swapaxes(dummy_dataset[0]['image'],0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36139c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dataset = CollectionsDataset(data=X_remaining,\n",
    "                                       labels=y_remaining,\n",
    "                                       num_classes=7,\n",
    "                                       transform=None)\n",
    "plt.imshow(dummy_dataset[0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264acdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/51677788/data-augmentation-in-pytorch\n",
    "\n",
    "# define some re-usable stuff\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 7\n",
    "BATCH_SIZE = 32\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # IMAGENET !\n",
    "     #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     transforms.RandomResizedCrop(size=224, scale=(0.55,1)),\n",
    "     #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "     transforms.RandomAdjustSharpness(sharpness_factor=3, p=0.5),\n",
    "     transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 3))\n",
    "    ])\n",
    "\n",
    "# push model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7db106",
   "metadata": {},
   "source": [
    "### Train UNI with balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f6e12",
   "metadata": {},
   "source": [
    "## Optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad374e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6a32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=7):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "    if device.type == 'cuda:0':\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32575b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer_ft = optim.Adam(model.parameters(), lr=1e-4, amsgrad=True) # was 1e-4\n",
    "#optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\"\"\"\n",
    "# Set a very small learning rate for the backbone and a higher one for the head\n",
    "optimizer_ft = optim.Adam([\n",
    "    {'params': backbone_params, 'lr': 1e-6, 'amsgrad': True},  \n",
    "    {'params': head_params, 'lr': 1e-4, 'amsgrad': True}      \n",
    "])\n",
    "\"\"\"\n",
    "\n",
    "lr_sch = None # lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.8) # was 10 and 0.8\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #device config\n",
    "\n",
    "seed_torch() # FIX SEED \n",
    "model_ft, history = train_model(model,\n",
    "                       device,\n",
    "                       train_transform,\n",
    "                       optimizer_ft,\n",
    "                       lr_sch,\n",
    "                       num_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb1b919-3028-451f-8d73-12e405e83922",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot( np.arange(len(history['train_loss'])), history['train_loss'], label='train' )\n",
    "plt.plot( np.arange(len(history['val_loss'])), history['val_loss'], label='val' )\n",
    "plt.legend(fontsize=18)\n",
    "plt.xlabel('epochs', fontsize=22)\n",
    "plt.ylabel('Cross entropy loss', fontsize=22)\n",
    "plt.tick_params(labelsize=18)\n",
    "#plt.yscale('log')\n",
    "plt.title('mcr=0.5, bs=32, AdamW, lr=1e-4, StepLR(step_size=5, gamma=0.8)')\n",
    "#plt.savefig('test3_aug3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a93db",
   "metadata": {},
   "source": [
    "### Save plot data as well !!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141528b2-e3d4-4de7-b764-a9ba4d53ce7d",
   "metadata": {},
   "source": [
    "### Nonorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b33e60c-f0c5-4acd-9645-225e0355ff3c",
   "metadata": {},
   "source": [
    "#### frozen backbone and linear head"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2096cf4-f9ce-4443-9778-ff773db168ed",
   "metadata": {},
   "source": [
    "with open('weights_train_uni_frozenbackbone_level4_nonorm_bracs_300epochs/history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4d5d7-d75f-4a36-ae41-d8701cce5b6e",
   "metadata": {},
   "source": [
    "#### frozen backbone and complex head"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c13877e-25a5-4d91-88f2-ac9a73d82b91",
   "metadata": {},
   "source": [
    "with open('weights_train_uni_frozenbackbone_complexhead_level4_nonorm_bracs_300epochs/history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f375a77c-3de8-42eb-a6c3-a4271553e632",
   "metadata": {},
   "source": [
    "#### finetune backbone as well and linear head"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0051379-60fa-45a0-9cd0-653eb027e994",
   "metadata": {},
   "source": [
    "with open('weights_train_uni_smallLRbackbone_level4_nonorm_bracs_100epochs/history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9285949-3dad-4d7c-85c9-4d4b1f716714",
   "metadata": {},
   "source": [
    "### Macenko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c567a-0e62-47ec-b145-0af68dba2477",
   "metadata": {},
   "source": [
    "#### frozen backbone and linear head"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76d5ec6e-3c9c-4645-a9d6-5cd7f6ab934d",
   "metadata": {},
   "source": [
    "with open('weights_train_uni_frozenbackbone_level4_macenkonorm_bracs_300epochs/history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d45dd7a-fdae-444b-b321-0eead85f5f27",
   "metadata": {},
   "source": [
    "#### finetune backbone as well and linear head"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7344cbf0-7470-4475-ae4c-194ca5a89772",
   "metadata": {},
   "source": [
    "with open('weights_train_uni_smallLRbackbone_level4_macenkonorm_bracs_100epochs/history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a88ddf-1dde-4160-a1a2-39aaf9e7f6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f5bb0f",
   "metadata": {},
   "source": [
    "### Generate learning curve for article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weights_train_uni_smallLRbackbone_complexhead_level4_nonorm_bracs_100epochs/history.json', 'r') as f:\n",
    "    nonorm_curve_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735da45-c46e-4e7b-b587-46baeb0cce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weights_train_uni_smallLRbackbone_complexhead_level4_macenko_bracs_100epochs/history.json', 'r') as f:\n",
    "    macenko_curve_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c22c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4), dpi=100)\n",
    "\n",
    "\n",
    "# First subplot\n",
    "axes[0].plot(np.arange(len(macenko_curve_data['train_loss'])), macenko_curve_data['train_loss'], label='train')\n",
    "axes[0].plot(np.arange(len(macenko_curve_data['val_loss'])), macenko_curve_data['val_loss'], label='val')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].set_xlabel('Epochs', fontsize=12)\n",
    "axes[0].set_ylabel('CE loss', fontsize=12)\n",
    "axes[0].tick_params(labelsize=12)\n",
    "# Add more xticks for the first subplot\n",
    "axes[0].set_xticks(np.arange(0, len(macenko_curve_data['train_loss'])+1, 25))\n",
    "axes[0].set_yticks([0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0])\n",
    "axes[0].text(0.5, -0.26, 'a)', transform=axes[0].transAxes, fontsize=12)\n",
    "\n",
    "# Second subplot\n",
    "\n",
    "# Second subplot\n",
    "axes[1].plot(np.arange(len(nonorm_curve_data['train_loss'])), nonorm_curve_data['train_loss'], label='train')\n",
    "axes[1].plot(np.arange(len(nonorm_curve_data['val_loss'])), nonorm_curve_data['val_loss'], label='val')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].set_xlabel('Epochs', fontsize=12)\n",
    "axes[1].set_ylabel('CE loss', fontsize=12)\n",
    "axes[1].tick_params(labelsize=12)\n",
    "# Add more xticks for the second subplot\n",
    "axes[1].set_xticks(np.arange(0, len(nonorm_curve_data['train_loss'])+1, 25))\n",
    "axes[1].set_yticks([0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0])\n",
    "axes[1].text(0.5, -0.26, 'b)', transform=axes[1].transAxes, fontsize=12)\n",
    "\n",
    "plt.tight_layout()  # Adjust the spacing between subplots if needed\n",
    "#plt.show()\n",
    "plt.savefig('../../article_plots/bracs_training_curves.svg', format='svg')\n",
    "plt.savefig('../../article_plots/bracs_training_curves.jpg', format='jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29fcc09",
   "metadata": {},
   "source": [
    "### Generating confusion matrix plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_transforms(mean = (0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    t = transforms.Compose(\n",
    "                        [transforms.ToTensor(),\n",
    "                         transforms.Normalize(mean = mean, std = std)])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21907a21",
   "metadata": {},
   "source": [
    "##### Nonorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bddf51-12be-4ec7-93d9-65214bf6f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls | grep nonorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d98db6-ca37-446f-9d70-ebe8dcddadbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217aeaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight_to_use = 'weights_train_uni_frozenbackbone_complexhead_level4_nonorm_bracs_300epochs/checkpoint_epoch_208_1.0834CE_61_acc.pth' # nonorm\n",
    "weight_to_use = 'weights_train_uni_smallLRbackbone_complexhead_level4_nonorm_bracs_100epochs/checkpoint_epoch_70_1.0144CE_62_acc.pth'#checkpoint_epoch_65_1.0277CE_63_acc.pth'\n",
    "loaded_model = torch.load( weight_to_use, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(loaded_model['model'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251744ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee234dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a torch tensor for the images\n",
    "imgs_tensor_nonorm = torch.zeros((X_val.shape[0], X_val.shape[3], X_val.shape[2], X_val.shape[1]), dtype=torch.float32)\n",
    "\n",
    "# Apply transforms to images\n",
    "for i in range(X_val.shape[0]):\n",
    "    imgs_tensor_nonorm[i] = default_transforms()(X_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbef71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_tensor_nonorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef3d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bracs_class_pred_val_all_nonorm = []\n",
    "\n",
    "# Create a data loader for the images\n",
    "data_loader = DataLoader( imgs_tensor_nonorm, batch_size=128, shuffle=False, num_workers=1)\n",
    "\n",
    "# Process the images using the feature extractor\n",
    "for img in data_loader:\n",
    "    img = img.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bracs_class_pred_val_nonorm = torch.nn.functional.softmax( model(img), dim=1 ) # softmax applied here !\n",
    "        #bracs_class_pred_val = torch.max( model(img), dim=1 ) # softmax applied here !\n",
    "\n",
    "    bracs_class_pred_val_all_nonorm.append(bracs_class_pred_val_nonorm.cpu().numpy())\n",
    "bracs_class_pred_val_all_nonorm =  np.concatenate( bracs_class_pred_val_all_nonorm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report( y_val, np.argmax( bracs_class_pred_val_all_nonorm, axis=1) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b1a2f-6d7d-4325-a19b-319bd56582ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the confusion matrix\n",
    "confusion_matrix = pd.crosstab( y_val, np.argmax(bracs_class_pred_val_all_nonorm, axis=1),\n",
    "                                rownames=['Real type'], colnames=['Predicted type'] )\n",
    "#print( confusion_matrix )\n",
    "\n",
    "# visualizng it on a heatmap\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title( 'Confusion matrix of ResNet50 - nonorm')\n",
    "sns.heatmap(confusion_matrix, annot=True, xticklabels=np.array(lb.classes_), \n",
    "            yticklabels=np.array(lb.classes_), annot_kws={\"size\": 20} )\n",
    "plt.tick_params(labelsize=12, rotation=25)\n",
    "plt.xlabel('Predicted type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2a7b9",
   "metadata": {},
   "source": [
    "##### Macenko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b19836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight_to_use = 'weights_train_uni_level4_macenkonorm_bracs_300epochs/checkpoint_epoch_83_1.1439CE_60_acc.pth' # macenko based on bracs\n",
    "## was pretty good: \n",
    "weight_to_use = 'weights_train_uni_smallLRbackbone_complexhead_level4_macenko_bracs_100epochs/checkpoint_epoch_70_1.0627CE_61_acc.pth' # macenko based on bracs\n",
    "#weight_to_use = 'weights_train_uni_smallLRbackbone_level4_macenkonorm_bracs_300epochs_OLD/checkpoint_epoch_158_1.0442CE_62_acc.pth' # macenko based on bracs\n",
    "\n",
    "loaded_model = torch.load( weight_to_use, map_location=torch.device('cuda'))\n",
    "model.load_state_dict(loaded_model['model'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79606d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a torch tensor for the images\n",
    "imgs_tensor_macenko = torch.zeros((X_val.shape[0], X_val.shape[3], X_val.shape[2], X_val.shape[1]), dtype=torch.float32)\n",
    "\n",
    "# Apply transforms to images\n",
    "for i in range(X_val.shape[0]):\n",
    "    imgs_tensor_macenko[i] = default_transforms()(X_val_macenko[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f244c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bracs_class_pred_val_all_macenko = []\n",
    "\n",
    "# Create a data loader for the images\n",
    "data_loader = DataLoader( imgs_tensor_macenko, batch_size=128, shuffle=False, num_workers=1)\n",
    "\n",
    "# Process the images using the feature extractor\n",
    "for img in data_loader:\n",
    "    img = img.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        bracs_class_pred_val_macenko = torch.nn.functional.softmax( model(img), dim=1 ) # softmax applied here !\n",
    "\n",
    "    bracs_class_pred_val_all_macenko.append(bracs_class_pred_val_macenko.cpu().numpy())\n",
    "bracs_class_pred_val_all_macenko =  np.concatenate( bracs_class_pred_val_all_macenko )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the confusion matrix\n",
    "confusion_matrix_macenko = pd.crosstab( y_val, np.argmax(bracs_class_pred_val_all_macenko, axis=1),\n",
    "                                rownames=['Real type'], colnames=['Predicted type'] )\n",
    "#print( confusion_matrix )\n",
    "\n",
    "# visualizng it on a heatmap\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title( 'Confusion matrix of ResNet50 - macenko')\n",
    "sns.heatmap(confusion_matrix_macenko, annot=True, xticklabels=np.array(lb.classes_), \n",
    "            yticklabels=np.array(lb.classes_), annot_kws={\"size\": 20},  )\n",
    "plt.tick_params(labelsize=12, rotation=25)\n",
    "plt.xlabel('Predicted type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycmap = plt.cm.get_cmap('bwr').reversed()\n",
    "# visualizng it on a heatmap\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title( 'Confusion matrix of ResNet50')\n",
    "sns.heatmap(confusion_matrix-confusion_matrix_macenko, annot=True, xticklabels=np.array(lb.classes_), \n",
    "            yticklabels=np.array(lb.classes_), annot_kws={\"size\": 20}, cmap=mycmap, vmin=-15, vmax=15 )\n",
    "plt.tick_params(labelsize=12, rotation=25)\n",
    "plt.xlabel('Predicted type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf08d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the confusion matrix\n",
    "confusion_matrix_nonorm_percent = confusion_matrix.div(confusion_matrix.sum(axis=1), axis=0)\n",
    "\n",
    "# visualizing the normalized confusion matrix on a heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title('Normalized Confusion matrix of ResNet50 - nonorm')\n",
    "sns.heatmap(confusion_matrix_nonorm_percent, annot=True, xticklabels=np.array(lb.classes_), \n",
    "            yticklabels=np.array(lb.classes_), annot_kws={\"size\": 20})\n",
    "plt.tick_params(labelsize=12, rotation=25)\n",
    "plt.xlabel('Predicted type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the confusion matrix\n",
    "confusion_matrix_macenko_percent = confusion_matrix_macenko.div(confusion_matrix_macenko.sum(axis=1), axis=0)\n",
    "\n",
    "# visualizing the normalized confusion matrix on a heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title('Normalized Confusion matrix of ResNet50 - macenko')\n",
    "sns.heatmap(confusion_matrix_macenko_percent, annot=True, xticklabels=np.array(lb.classes_), \n",
    "            yticklabels=np.array(lb.classes_), annot_kws={\"size\": 20})\n",
    "plt.tick_params(labelsize=12, rotation=25)\n",
    "plt.xlabel('Predicted type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d7ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a07e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the confusion matrix\n",
    "confusion_matrix_macenko_percent = confusion_matrix_macenko.div(confusion_matrix_macenko.sum(axis=1), axis=0)\n",
    "\n",
    "# calculate percentage deviations from the non-normalized confusion matrix\n",
    "percentage_deviations = ( ( confusion_matrix_macenko_percent / confusion_matrix_nonorm_percent ) - 1 ) *100\n",
    "\n",
    "# visualizing the normalized confusion matrix on a heatmap with percentage deviations\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title('Normalized Confusion matrix of ResNet50 - macenko with Percentage Deviations')\n",
    "sns.heatmap(confusion_matrix_macenko_percent, annot=True, xticklabels=np.array(lb.classes_), \n",
    "            yticklabels=np.array(lb.classes_), annot_kws={\"size\": 20}, cmap='viridis')\n",
    "plt.tick_params(labelsize=12, rotation=25)\n",
    "\n",
    "# add percentage deviations to the top right of each tile\n",
    "for i in range(confusion_matrix_macenko_percent.shape[0]):\n",
    "    for j in range(confusion_matrix_macenko_percent.shape[1]):\n",
    "\n",
    "        if i == j:\n",
    "            text = f'{np.round(percentage_deviations.iloc[i, j],2)}%'\n",
    "            plt.text(j + 0.7, i + 0.1, text, fontsize=12, ha='center', va='center', color='green' if percentage_deviations.iloc[i, j] >= 0 else 'red' )\n",
    "        \n",
    "        else:\n",
    "            text = f'{-np.round(percentage_deviations.iloc[i, j],2)}%'\n",
    "            plt.text(j + 0.7, i + 0.1, text, fontsize=12, ha='center', va='center', color='green' if percentage_deviations.iloc[i, j] < 0 else 'red' )\n",
    "\n",
    "            \n",
    "plt.xlabel('Predicted type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report( y_val, np.argmax( bracs_class_pred_val_all_nonorm, axis=1) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1668eaf-d7fe-43d9-afae-c325ef066042",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report( y_val, np.argmax( bracs_class_pred_val_all_macenko, axis=1) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf462ac-bfca-471d-8ce4-05ac60a25ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63653409",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for n in range(confusion_matrix_nonorm_percent.shape[0]):\n",
    "    acc += confusion_matrix_nonorm_percent.iloc[n,n]\n",
    "acc /= n+1\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for n in range(confusion_matrix_macenko_percent.shape[0]):\n",
    "    acc += confusion_matrix_macenko_percent.iloc[n,n]\n",
    "acc /= n+1\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af9167e-5f01-4f8c-a78c-d96c0e134a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print individual class accuracies\n",
    "class_accuracies = []\n",
    "for i in range(confusion_matrix_nonorm_percent.shape[0]):\n",
    "    # Since the matrix already contains percentages of correct predictions in the diagonal,\n",
    "    # we directly take those as class accuracies.\n",
    "    class_accuracy = confusion_matrix_nonorm_percent.iloc[i, i]\n",
    "    class_accuracies.append(class_accuracy)\n",
    "    print(f\"Accuracy for {lb.classes_[i]}: {np.round(class_accuracy*100,2)}%\")\n",
    "\n",
    "# Overall accuracy\n",
    "overall_acc = sum(class_accuracies) / len(class_accuracies)\n",
    "print(f\"\\nOverall Accuracy: {overall_acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dbef9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee8222-c4b7-4dde-b5fd-da4239dc3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print individual class accuracies\n",
    "class_accuracies = []\n",
    "for i in range(confusion_matrix_macenko_percent.shape[0]):\n",
    "    # Since the matrix already contains percentages of correct predictions in the diagonal,\n",
    "    # we directly take those as class accuracies.\n",
    "    class_accuracy = confusion_matrix_macenko_percent.iloc[i, i]\n",
    "    class_accuracies.append(class_accuracy)\n",
    "    print(f\"Accuracy for {lb.classes_[i]}: {np.round(class_accuracy*100,2)}%\")\n",
    "\n",
    "# Overall accuracy\n",
    "overall_acc = sum(class_accuracies) / len(class_accuracies)\n",
    "print(f\"\\nOverall Accuracy: {overall_acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d40be-25fb-4d67-b90c-f7a8b901d5db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
